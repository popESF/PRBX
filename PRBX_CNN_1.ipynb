{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMzQKkAjlQVGIryHM/aUvT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset paths and parameters\n",
        "data_dir = '/content/drive/My Drive/my_dataset/data'\n",
        "image_height = 100  # Adjust dimensions as per your dataset\n",
        "image_width = 100\n",
        "batch_size = 32\n",
        "num_classes = 6  # Number of gesture classes\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.30  # Specify validation split\n",
        ")\n",
        "\n",
        "# Load data using ImageDataGenerator with validation split\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Specify 'training' subset for training data\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'  # Specify 'validation' subset for validation data\n",
        ")\n",
        "\n",
        "# Define test data generator\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Load test data using the test data generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/my_dataset/test',  # Path to test directory\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Ensure that data isn't shuffled\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Create and compile the model (assuming you have a function called create_model)\n",
        "input_shape = (image_height, image_width, 3)  # Adjust dimensions as per your dataset\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 30  # Adjust as needed\n",
        "model.fit(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "# Save the trained model\n",
        "model.save('/content/drive/My Drive/PRBX-CNN_3.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNh8oCpmwWOq",
        "outputId": "81fd45d9-9508-46c0-8cb5-771949ed9952"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 42 images belonging to 6 classes.\n",
            "Found 12 images belonging to 6 classes.\n",
            "Found 6 images belonging to 6 classes.\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 334ms/step - loss: 1.7569 - accuracy: 0.2143 - val_loss: 1.5878 - val_accuracy: 0.2500\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 277ms/step - loss: 1.7795 - accuracy: 0.1667 - val_loss: 1.5331 - val_accuracy: 0.3333\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 285ms/step - loss: 1.6815 - accuracy: 0.1667 - val_loss: 1.5519 - val_accuracy: 0.5833\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 1.5583 - accuracy: 0.3333 - val_loss: 1.4295 - val_accuracy: 0.5000\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 1.4968 - accuracy: 0.4524 - val_loss: 1.3740 - val_accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 1.4263 - accuracy: 0.4524 - val_loss: 1.4363 - val_accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 274ms/step - loss: 1.2620 - accuracy: 0.5714 - val_loss: 1.2590 - val_accuracy: 0.5000\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 209ms/step - loss: 1.7165 - accuracy: 0.4048 - val_loss: 0.9730 - val_accuracy: 0.7500\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 1.3548 - accuracy: 0.5238 - val_loss: 1.1864 - val_accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 1.3894 - accuracy: 0.5952 - val_loss: 1.2445 - val_accuracy: 0.4167\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 1.3429 - accuracy: 0.5476 - val_loss: 1.0876 - val_accuracy: 0.9167\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 1.0715 - accuracy: 0.6667 - val_loss: 1.0740 - val_accuracy: 0.6667\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 260ms/step - loss: 1.1615 - accuracy: 0.6190 - val_loss: 1.1389 - val_accuracy: 0.7500\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 1.3050 - accuracy: 0.4524 - val_loss: 1.1559 - val_accuracy: 0.6667\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 1.0827 - accuracy: 0.6429 - val_loss: 0.9559 - val_accuracy: 0.6667\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 286ms/step - loss: 1.1275 - accuracy: 0.7143 - val_loss: 0.8300 - val_accuracy: 0.7500\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 328ms/step - loss: 0.8731 - accuracy: 0.7143 - val_loss: 0.9142 - val_accuracy: 0.6667\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 263ms/step - loss: 0.7676 - accuracy: 0.7381 - val_loss: 0.7847 - val_accuracy: 0.5833\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 199ms/step - loss: 0.8430 - accuracy: 0.6429 - val_loss: 0.6754 - val_accuracy: 0.6667\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 1s 262ms/step - loss: 0.8780 - accuracy: 0.6429 - val_loss: 0.7658 - val_accuracy: 0.6667\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 396ms/step - loss: 0.7843 - accuracy: 0.7143 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.5538 - accuracy: 0.7619 - val_loss: 0.3498 - val_accuracy: 0.8333\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 1s 429ms/step - loss: 0.7592 - accuracy: 0.6905 - val_loss: 0.4583 - val_accuracy: 0.7500\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 0.6361 - accuracy: 0.7619 - val_loss: 0.2863 - val_accuracy: 0.8333\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 325ms/step - loss: 0.6438 - accuracy: 0.7381 - val_loss: 0.6535 - val_accuracy: 0.6667\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 255ms/step - loss: 0.5386 - accuracy: 0.8333 - val_loss: 0.3598 - val_accuracy: 0.9167\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 256ms/step - loss: 0.4473 - accuracy: 0.7857 - val_loss: 0.3138 - val_accuracy: 0.8333\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 275ms/step - loss: 0.5723 - accuracy: 0.7143 - val_loss: 0.4408 - val_accuracy: 0.8333\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 275ms/step - loss: 0.5171 - accuracy: 0.7857 - val_loss: 0.2092 - val_accuracy: 0.9167\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 0.4298 - accuracy: 0.9048 - val_loss: 0.5450 - val_accuracy: 0.8333\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3282 - accuracy: 0.8333\n",
            "Test Accuracy: 0.8333333134651184\n"
          ]
        }
      ]
    }
  ]
}